{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming in NLTK\n",
    "\n",
    "\n",
    "Stemming is a text normalization technique used in natural language processing (NLP) and information retrieval to reduce words to their base or root form, called the \"stem.\"\n",
    "\n",
    "\n",
    "**Key Points about Stemming:**\n",
    "\n",
    "1. **Base or Root Form**: Stemming algorithms aim to remove affixes from words, such as prefixes, suffixes, and inflectional endings, to derive the base form of the word.\n",
    "\n",
    "2. **Equivalence**: Stemming allows different variations of a word to be treated as the same word. For example, \"running,\" \"ran,\" and \"runs\" would all be stemmed to the common base form \"run.\"\n",
    "\n",
    "3. **Heuristic Approach**: Stemming algorithms often use simple heuristic rules to remove affixes. While these rules are effective in many cases, they may not always produce correct linguistic stems.\n",
    "\n",
    "4. **Speed**: Stemming algorithms are generally fast and suitable for processing large volumes of text. However, they may produce stems that are not valid words in the language.\n",
    "\n",
    "5. **Porter Stemmer**: The Porter Stemmer is one of the most well-known stemming algorithms, developed by Martin Porter in 1980. It applies a series of heuristic rules to reduce words to their stems.\n",
    "\n",
    "**Example of Stemming:**\n",
    "\n",
    "- **Original**: \"running\"\n",
    "- **Stemmed**: \"run\"\n",
    "\n",
    "- **Original**: \"cats\"\n",
    "- **Stemmed**: \"cat\"\n",
    "\n",
    "- **Original**: \"writing\"\n",
    "- **Stemmed**: \"write\"\n",
    "\n",
    "**Limitations of Stemming:**\n",
    "\n",
    "1. **Overstemming**: Stemming may sometimes remove too many affixes, leading to stems that are not valid words or that lose their meaning. For example, \"universally\" might be stemmed to \"univers\" instead of \"universal.\"\n",
    "\n",
    "2. **Understemming**: Conversely, stemming may also fail to remove all affixes, leaving the stem in an incorrect or incomplete form. For example, \"happiness\" might be stemmed to \"happi\" instead of \"happy.\"\n",
    "\n",
    "3. **Language Dependence**: Stemming algorithms are often language-dependent and may not perform well for languages with complex morphology or irregular word forms.\n",
    "\n",
    "**Applications of Stemming:**\n",
    "\n",
    "1. **Information Retrieval**: Stemming is used in search engines to improve retrieval by treating different forms of words as equivalent.\n",
    "\n",
    "2. **Text Mining**: Stemming is employed in text analysis tasks such as clustering, classification, and topic modeling to reduce dimensionality and improve performance.\n",
    "\n",
    "3. **Text Normalization**: Stemming is a step in text preprocessing pipelines to prepare text data for further analysis or processing.\n",
    "\n",
    "4. **Language Processing**: Stemming is used in various language processing tasks, including machine translation, sentiment analysis, and named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text= 'Stemming is a text normalization technique used in natural language processing (NLP) and information retrieval to reduce words to their base or root form, called the \"stem.\"'\n",
    "tokens = word_tokenize(text=sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Stemming\t\tStemmed: stem\n",
      "Original: is\t\tStemmed: is\n",
      "Original: a\t\tStemmed: a\n",
      "Original: text\t\tStemmed: text\n",
      "Original: normalization\t\tStemmed: normal\n",
      "Original: technique\t\tStemmed: techniqu\n",
      "Original: used\t\tStemmed: use\n",
      "Original: in\t\tStemmed: in\n",
      "Original: natural\t\tStemmed: natur\n",
      "Original: language\t\tStemmed: languag\n",
      "Original: processing\t\tStemmed: process\n",
      "Original: (\t\tStemmed: (\n",
      "Original: NLP\t\tStemmed: nlp\n",
      "Original: )\t\tStemmed: )\n",
      "Original: and\t\tStemmed: and\n",
      "Original: information\t\tStemmed: inform\n",
      "Original: retrieval\t\tStemmed: retriev\n",
      "Original: to\t\tStemmed: to\n",
      "Original: reduce\t\tStemmed: reduc\n",
      "Original: words\t\tStemmed: word\n",
      "Original: to\t\tStemmed: to\n",
      "Original: their\t\tStemmed: their\n",
      "Original: base\t\tStemmed: base\n",
      "Original: or\t\tStemmed: or\n",
      "Original: root\t\tStemmed: root\n",
      "Original: form\t\tStemmed: form\n",
      "Original: ,\t\tStemmed: ,\n",
      "Original: called\t\tStemmed: call\n",
      "Original: the\t\tStemmed: the\n",
      "Original: ``\t\tStemmed: ``\n",
      "Original: stem\t\tStemmed: stem\n",
      "Original: .\t\tStemmed: .\n",
      "Original: ''\t\tStemmed: ''\n"
     ]
    }
   ],
   "source": [
    "stemmed_words_Po = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "# Printing the original words and their stems\n",
    "for i in range(len(tokens)):\n",
    "    print(f\"Original: {tokens[i]}\\t\\tStemmed: {stemmed_words_Po[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Stemming\t\tLStemmed: stem\t\tPoStemme:stem\n",
      "Original: is\t\tLStemmed: is\t\tPoStemme:is\n",
      "Original: a\t\tLStemmed: a\t\tPoStemme:a\n",
      "Original: text\t\tLStemmed: text\t\tPoStemme:text\n",
      "Original: normalization\t\tLStemmed: norm\t\tPoStemme:normal\n",
      "Original: technique\t\tLStemmed: techn\t\tPoStemme:techniqu\n",
      "Original: used\t\tLStemmed: us\t\tPoStemme:use\n",
      "Original: in\t\tLStemmed: in\t\tPoStemme:in\n",
      "Original: natural\t\tLStemmed: nat\t\tPoStemme:natur\n",
      "Original: language\t\tLStemmed: langu\t\tPoStemme:languag\n",
      "Original: processing\t\tLStemmed: process\t\tPoStemme:process\n",
      "Original: (\t\tLStemmed: (\t\tPoStemme:(\n",
      "Original: NLP\t\tLStemmed: nlp\t\tPoStemme:nlp\n",
      "Original: )\t\tLStemmed: )\t\tPoStemme:)\n",
      "Original: and\t\tLStemmed: and\t\tPoStemme:and\n",
      "Original: information\t\tLStemmed: inform\t\tPoStemme:inform\n",
      "Original: retrieval\t\tLStemmed: retriev\t\tPoStemme:retriev\n",
      "Original: to\t\tLStemmed: to\t\tPoStemme:to\n",
      "Original: reduce\t\tLStemmed: reduc\t\tPoStemme:reduc\n",
      "Original: words\t\tLStemmed: word\t\tPoStemme:word\n",
      "Original: to\t\tLStemmed: to\t\tPoStemme:to\n",
      "Original: their\t\tLStemmed: their\t\tPoStemme:their\n",
      "Original: base\t\tLStemmed: bas\t\tPoStemme:base\n",
      "Original: or\t\tLStemmed: or\t\tPoStemme:or\n",
      "Original: root\t\tLStemmed: root\t\tPoStemme:root\n",
      "Original: form\t\tLStemmed: form\t\tPoStemme:form\n",
      "Original: ,\t\tLStemmed: ,\t\tPoStemme:,\n",
      "Original: called\t\tLStemmed: cal\t\tPoStemme:call\n",
      "Original: the\t\tLStemmed: the\t\tPoStemme:the\n",
      "Original: ``\t\tLStemmed: ``\t\tPoStemme:``\n",
      "Original: stem\t\tLStemmed: stem\t\tPoStemme:stem\n",
      "Original: .\t\tLStemmed: .\t\tPoStemme:.\n",
      "Original: ''\t\tLStemmed: ''\t\tPoStemme:''\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "# Printing the original words and their stems\n",
    "for i in range(len(tokens)):\n",
    "    print(f\"Original: {tokens[i]}\\t\\tLStemmed: {stemmed_words[i]}\\t\\tPoStemme:{stemmed_words_Po[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
